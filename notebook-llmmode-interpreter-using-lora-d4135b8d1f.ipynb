{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T15:10:33.405353Z","iopub.execute_input":"2024-11-12T15:10:33.406162Z","iopub.status.idle":"2024-11-12T15:10:49.042376Z","shell.execute_reply.started":"2024-11-12T15:10:33.406097Z","shell.execute_reply":"2024-11-12T15:10:49.041254Z"}},"outputs":[{"name":"stdout","text":"Collecting peft\n  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.13.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")\nimport os\nos.environ[\"HF_TOKEN\"] = secret_value_0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T15:10:49.044494Z","iopub.execute_input":"2024-11-12T15:10:49.044913Z","iopub.status.idle":"2024-11-12T15:10:49.140179Z","shell.execute_reply.started":"2024-11-12T15:10:49.044871Z","shell.execute_reply":"2024-11-12T15:10:49.139280Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def anti_dumbass_check(base_model_path, adapter_model_path):\n    base_model_path = base_model_path.lower()\n    adapter_model_path = adapter_model_path.lower()\n    if \"3b\" in adapter_model_path and \"3b\" not in base_model_path:\n        raise ValueError(\"Different Model\")\n    if \"1b\" in adapter_model_path and \"1b\" not in base_model_path:\n        raise ValueError(\"Different Model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T15:10:49.141907Z","iopub.execute_input":"2024-11-12T15:10:49.142247Z","iopub.status.idle":"2024-11-12T15:10:49.148130Z","shell.execute_reply.started":"2024-11-12T15:10:49.142212Z","shell.execute_reply":"2024-11-12T15:10:49.147137Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nfrom peft import PeftModel\nimport torch\n\n# Path to the base model (e.g., a pretrained model like \"gpt2\" or \"facebook/opt\")\nbase_model_path = \"meta-llama/Llama-3.2-3B-Instruct\"\nadapter_model_path = \"Steven10429/autotrain-llama-3b-g82lo\"  # Path to your adapter model\nanti_dumbass_check(base_model_path, adapter_model_path)\n\n\n# Load the tokenizer from the base model\ntokenizer = AutoTokenizer.from_pretrained(base_model_path)\n\n# Load the base model\nbase_model = AutoModelForCausalLM.from_pretrained(\n    base_model_path,\n    device_map=\"auto\",\n    torch_dtype=\"auto\"\n).eval()\n\n# Load the adapter weights using peft\nmodel = PeftModel.from_pretrained(base_model, adapter_model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T15:11:08.103262Z","iopub.execute_input":"2024-11-12T15:11:08.103721Z","iopub.status.idle":"2024-11-12T15:13:55.731192Z","shell.execute_reply.started":"2024-11-12T15:11:08.103655Z","shell.execute_reply":"2024-11-12T15:13:55.730076Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5db594a6bc5e4154a8fb874919a6c8a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"955ad930063b4c88a510ef3923bd4b8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2366d7767af64704a40cbc43b42bad87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25af6a33a9684562a9e2b023e87971d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d1e61e5e0454b199e6194e555c3d533"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2791137830ab4ff6ac755bd5f0d522a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e844629c5dc46249342876e8c28e22a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a8a03ad6d1e4bcba2fb76bcdcb1975c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"047c31dc1b1a4a27bb0a978e5e7d86a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3417fff279434583ab38346f3a58cb2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78147eb8b4554dedb13fa1b2a3844646"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/97.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"340671bd0f2442bdb9590988a9ecde51"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Example input for text generation\ninput_text = \"\"\"第1章 可爱的魔女“我真可爱！”这是沐奇奇每天醒来，看着镜子里的自己的第一反应\"\"\"\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n\n# Generate text\noutput_ids = model.generate(input_ids, max_length=50)\nresponse = tokenizer.decode(output_ids[0], skip_special_tokens=True)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T15:13:55.733349Z","iopub.execute_input":"2024-11-12T15:13:55.733914Z","iopub.status.idle":"2024-11-12T15:13:56.955456Z","shell.execute_reply.started":"2024-11-12T15:13:55.733872Z","shell.execute_reply":"2024-11-12T15:13:56.954439Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nStarting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","output_type":"stream"},{"name":"stdout","text":"第1章 可爱的魔女“我真可爱！”这是沐奇奇每天醒来，看着镜子里的自己的第一反应。\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"input_text = \"\"\"沐奇奇\"\"\"\ntokenizer.decode(model.generate(tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\"), max_length=10, repetition_penalty=2.0)[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T15:45:32.515200Z","iopub.execute_input":"2024-11-12T15:45:32.515642Z","iopub.status.idle":"2024-11-12T15:45:33.034329Z","shell.execute_reply.started":"2024-11-12T15:45:32.515604Z","shell.execute_reply":"2024-11-12T15:45:33.033225Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'沐奇奇拿起《厄'"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}